{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sabrinaaquino/rag_chatbot/blob/main/simple_rag_ai_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building a RAG Chatbot with Qdrant, Gemma3, and Docling"
      ],
      "metadata": {
        "id": "NF7aEGyfftnn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing the necessary Python libraries."
      ],
      "metadata": {
        "id": "bJC5D2sURds4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDAL7fGoLiKq"
      },
      "outputs": [],
      "source": [
        "#!pip install qdrant-client docling fastembed google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the libraries we'll use"
      ],
      "metadata": {
        "id": "PLcZoGiORWjE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from qdrant_client import QdrantClient, models\n",
        "from docling.document_converter import DocumentConverter\n",
        "from docling.chunking import HybridChunker\n",
        "from fastembed import TextEmbedding\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "mRM9ykQ2LxO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`DocumentConverter()` is reading and converting documents (like PDFs, Word docs, etc.) into a structured format."
      ],
      "metadata": {
        "id": "l1rKPqFIRKCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source = \"data/the_rust_workbook.pdf\"\n",
        "document = DocumentConverter().convert(source=source).document"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fOSg5vrMb89",
        "outputId": "8a2aa949-526b-4d52-de27-3c6fc569caed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.11/dist-packages/docling/pipeline/standard_pdf_pipeline.py:262: RuntimeWarning: Mean of empty slice\n",
            "  np.nanmean(\n",
            "/usr/local/lib/python3.11/dist-packages/docling/pipeline/standard_pdf_pipeline.py:267: RuntimeWarning: Mean of empty slice\n",
            "  np.nanmean(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(document)"
      ],
      "metadata": {
        "id": "u6vFs_dVSqXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Processing a document into smaller, manageable parts called \"chunks\". To ensure that chunks do not exceed the 256-token limit of the `all-MiniLM-L6-v2` model, let's set the max_tokens parameter to 256:"
      ],
      "metadata": {
        "id": "FxkYZ41ZVlQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_tokenizer = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "chunker = HybridChunker(tokenizer=chunk_tokenizer)\n",
        "chunks = chunker.chunk(dl_doc=document, max_tokens=256)"
      ],
      "metadata": {
        "id": "cr-ER8-PO1YP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take each element from the list `chunks`, extract its `.text` attribute, and build a new list containing just the texts from each chunk"
      ],
      "metadata": {
        "id": "EBhgKUBMVbW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_chunks = [c.text for c in chunks]"
      ],
      "metadata": {
        "id": "8Va91k4SU2Wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(text_chunks))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ky1QdjrGVAP2",
        "outputId": "fbfca899-5f10-4752-9848-ab99a3a72426"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model = TextEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
        "embeddings = list(embedding_model.embed(text_chunks))"
      ],
      "metadata": {
        "id": "Pz4uvaMNPM48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(embeddings))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZK3qpJQXUEgQ",
        "outputId": "0fe206d6-51dd-45ed-9a73-3069c8527ccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client = QdrantClient(\":memory:\")"
      ],
      "metadata": {
        "id": "VDA8_HqoRzDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "collection_name = \"rust-book\""
      ],
      "metadata": {
        "id": "IKsSwRt2TpJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = len(embeddings[0])\n",
        "\n",
        "client.create_collection(\n",
        "    collection_name=collection_name,\n",
        "    vectors_config=models.VectorParams(\n",
        "      size=embedding_dim,\n",
        "      distance=models.Distance.COSINE\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mM8PhYxyXAE5",
        "outputId": "6c015cd7-d2e0-4eac-ab1e-9e9286468c91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "points = [\n",
        "    models.PointStruct(id=i, vector=vec, payload={\"text\": text_chunks[i]})\n",
        "    for i, vec in enumerate(embeddings)\n",
        "]"
      ],
      "metadata": {
        "id": "E2kP9U0XZeUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(points[0].vector))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiXwcFVIZwmU",
        "outputId": "e4ff0038-dfd5-40a4-b459-40c45169121e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client.upload_points(\n",
        "    collection_name=collection_name,\n",
        "    points=points,\n",
        ")"
      ],
      "metadata": {
        "id": "aqwa--5UPfM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_text=\"Who is the author of this book\"\n",
        "query_vector = list(embedding_model.embed(query_text))[0]"
      ],
      "metadata": {
        "id": "H8pDb3nSaILT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_result = client.query_points(\n",
        "    collection_name=collection_name,\n",
        "    query=query_vector,\n",
        "    limit = 3,\n",
        ")\n",
        "print(search_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtUZxm9hWg28",
        "outputId": "17abcb83-961a-4659-f894-dacda57c6b62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "points=[ScoredPoint(id=3, version=0, score=0.7342091347160316, payload={'text': 'The author has made every effort to ensure the accuracy and completeness of the information contained in this book. However, the author assumes no responsibility for errors, omissions, or contrary interpretations of the subject matter.\\nThis publication is offered with the understanding that the author is not engaged in rendering legal, financial, professional, or technical advice or services. If legal, financial, or other expert assistance is required, the services of a competent professional should be sought.\\nIn no event shall the author or any distributor of this book be liable for any special, incidental, indirect, or consequential damages whatsoever arising out of or in connection with the use or inability to use this book, even if the author or distributor has been advised of the possibility of such damages.'}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=2, version=0, score=0.6722378697462688, payload={'text': \"The information in this book is provided 'as is' without any guarantees of completeness, accuracy, usefulness, or timeliness. The author disclaims any liability for any damages or losses incurred directly or indirectly in connection with the use of or reliance on the contents of this book.\"}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=17, version=0, score=0.6626092340486593, payload={'text': 'If you find anything in this book that needs to be corrected or improved, or if you simply want to provide feedback (even positive feedback is welcome!), please feel free to contact me.\\nI appreciate all constructive input and would love to hear from you. You can reach me at me@francescociulla.com using the subject line [Rust Workbook Feedback].\\nThank you for helping make this workbook better!'}, vector=None, shard_key=None, order_value=None)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context = \"\\n\\n\".join(hit.payload[\"text\"] for hit in search_result.points)"
      ],
      "metadata": {
        "id": "4mE9hMkicagM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdXtiPhwcpUN",
        "outputId": "18eb5a8d-16e9-4d5f-abe2-6be4f3ff4ac7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The author has made every effort to ensure the accuracy and completeness of the information contained in this book. However, the author assumes no responsibility for errors, omissions, or contrary interpretations of the subject matter.\n",
            "This publication is offered with the understanding that the author is not engaged in rendering legal, financial, professional, or technical advice or services. If legal, financial, or other expert assistance is required, the services of a competent professional should be sought.\n",
            "In no event shall the author or any distributor of this book be liable for any special, incidental, indirect, or consequential damages whatsoever arising out of or in connection with the use or inability to use this book, even if the author or distributor has been advised of the possibility of such damages.\n",
            "\n",
            "The information in this book is provided 'as is' without any guarantees of completeness, accuracy, usefulness, or timeliness. The author disclaims any liability for any damages or losses incurred directly or indirectly in connection with the use of or reliance on the contents of this book.\n",
            "\n",
            "If you find anything in this book that needs to be corrected or improved, or if you simply want to provide feedback (even positive feedback is welcome!), please feel free to contact me.\n",
            "I appreciate all constructive input and would love to hear from you. You can reach me at me@francescociulla.com using the subject line [Rust Workbook Feedback].\n",
            "Thank you for helping make this workbook better!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have done the retrieval, let's do the generation."
      ],
      "metadata": {
        "id": "3aXV-gabb1ut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key=userdata.get('gemini-api-key'))"
      ],
      "metadata": {
        "id": "s3eqrvMke5Lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "List available models"
      ],
      "metadata": {
        "id": "bCdQEj0dgp6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 798
        },
        "id": "NSKN20BngaI1",
        "outputId": "9032f394-cc7a-4dbc-cbc8-4093d4ef8a5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-pro-vision\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-1.5-pro-001\n",
            "models/gemini-1.5-pro-002\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-flash-001\n",
            "models/gemini-1.5-flash-001-tuning\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-002\n",
            "models/gemini-1.5-flash-8b\n",
            "models/gemini-1.5-flash-8b-001\n",
            "models/gemini-1.5-flash-8b-latest\n",
            "models/gemini-1.5-flash-8b-exp-0827\n",
            "models/gemini-1.5-flash-8b-exp-0924\n",
            "models/gemini-2.5-pro-exp-03-25\n",
            "models/gemini-2.5-pro-preview-03-25\n",
            "models/gemini-2.5-flash-preview-04-17\n",
            "models/gemini-2.5-flash-preview-05-20\n",
            "models/gemini-2.5-flash-preview-04-17-thinking\n",
            "models/gemini-2.5-pro-preview-05-06\n",
            "models/gemini-2.0-flash-exp\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-exp-image-generation\n",
            "models/gemini-2.0-flash-lite-001\n",
            "models/gemini-2.0-flash-lite\n",
            "models/gemini-2.0-flash-preview-image-generation\n",
            "models/gemini-2.0-flash-lite-preview-02-05\n",
            "models/gemini-2.0-flash-lite-preview\n",
            "models/gemini-2.0-pro-exp\n",
            "models/gemini-2.0-pro-exp-02-05\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.0-flash-thinking-exp-01-21\n",
            "models/gemini-2.0-flash-thinking-exp\n",
            "models/gemini-2.0-flash-thinking-exp-1219\n",
            "models/gemini-2.5-flash-preview-tts\n",
            "models/gemini-2.5-pro-preview-tts\n",
            "models/learnlm-2.0-flash-experimental\n",
            "models/gemma-3-1b-it\n",
            "models/gemma-3-4b-it\n",
            "models/gemma-3-12b-it\n",
            "models/gemma-3-27b-it\n",
            "models/gemma-3n-e4b-it\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(\"gemma-3-27b-it\")"
      ],
      "metadata": {
        "id": "ZVAHFFlOfoJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"You are a helpful assistant. Use the following context to answer the user's question and if you can't find the answer in the context, say you don't know.\n",
        "\n",
        "Context: {context}\n",
        "Question: {query_text}\n",
        "Answer:\"\"\""
      ],
      "metadata": {
        "id": "4pdEW57kdNLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(prompt)\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "braDRLm_gThn",
        "outputId": "aad87baa-b298-41f5-98e1-eedc27138865"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The author is Francescociulla, and you can reach them at me@francescociulla.com.\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining it as a function"
      ],
      "metadata": {
        "id": "1MVK-3ckhXvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rag_respond_with_gemini(query_text):\n",
        "\n",
        "    # Step 1: Embed the query\n",
        "    query_vector = list(embedding_model.embed(query_text))[0]\n",
        "\n",
        "    # Step 2: Retrieve relevant context from Qdrant\n",
        "    search_results = client.query_points(\n",
        "      collection_name=collection_name,\n",
        "      query=query_vector,\n",
        "      limit = 3,\n",
        "    )\n",
        "\n",
        "    context = \"\\n\\n\".join(hit.payload[\"text\"] for hit in search_results.points)\n",
        "\n",
        "    # Step 3: Format prompt for Gemini\n",
        "    prompt = f\"\"\"You are a helpful assistant.\n",
        "\n",
        "Use the context below to answer the user's question.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {query_text}\n",
        "Answer:\"\"\"\n",
        "\n",
        "    # Step 4: Generate with Gemini\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text.strip()"
      ],
      "metadata": {
        "id": "USUQIOZvg4jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = rag_respond_with_gemini(\"Tell me about ownership in Rust\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "qw8NZuv-hzm2",
        "outputId": "1a438283-b5d2-48aa-d895-e53a3aea8220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "According to the provided text, ownership in Rust is a key part of the language's system for managing memory safely. It's explored in an exercise where you move a variable's value to another, and observe what happens when trying to use the original. The text also explains that ownership works *with* lifetimes to prevent \"dangling references\" â€“ a common source of bugs and crashes in other languages.\n",
            "\n",
            "You can also *borrow* values using the `&` operator instead of moving them, which demonstrates how borrowing works in Rust.\n",
            "\n",
            "The topic of ownership is covered in more detail in Chapter 2 of the book.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = rag_respond_with_gemini(\"Why Rust is a good programming language?\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "XFlaCJdJi3lP",
        "outputId": "45982a47-26c5-4e60-ef0a-5bb927ba065b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "According to the text, Rust is a good programming language because of its **performance, safety, and concurrency capabilities**. It was also voted the **most admired programming language** in the Stack Overflow Developer Survey 2024, and has **unique features, especially in memory management**. Additionally, it helps you write **organized and easier to manage** code through features like **functions and variables**.\n"
          ]
        }
      ]
    }
  ]
}